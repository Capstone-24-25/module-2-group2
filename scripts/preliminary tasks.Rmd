---
title: "preliminary taks"
output:
  html_document: default
  pdf_document: default
date: "2024-11-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Functions and Libraries

```{r}
# Loading the libraries
library(tidyverse)
require(tidytext)
require(textstem)
require(rvest)
require(qdapRegex)
require(stopwords)
require(tokenizers)
library(tidymodels)
library(modelr)
library(Matrix)
library(sparsesvd)
library(glmnet)

# Loading the Data
source('preprocessing.R')
load("../data/claims-raw.RData")
load("../data/claims-clean-example.RData")

# PCA project function
# Function
projection_fn <- function(.dtm, .prop){
  # Coerce feature matrix to sparse
  dtm_mx <- .dtm %>%
    as.matrix() %>%
    as('sparseMatrix')
  # Compute svd
  svd_out <- sparsesvd(dtm_mx)
  # Select number of projections
  var_df <- tibble(var = svd_out$d^2) %>%
    mutate(pc = row_number(),
           cumulative = cumsum(var)/sum(var))
  n_pc <- which.min(var_df$cumulative < .prop)
  # Extract loadings
  loadings <- svd_out$v[, 1:n_pc] %>% as.matrix()
  # Extract scores
  scores <- (dtm_mx %*% svd_out$v[, 1:n_pc]) %>% as.matrix()
  # Adjust names
  colnames(loadings) <- colnames(scores) <- paste('pc', 1:n_pc, sep = '')
  # Output
    out <- list(n_pc = n_pc,
              var = var_df,
              projection = loadings,
              data = as_tibble(scores))
  return(out)
}

# Reproject test data
reproject_fn <- function(.dtm, .projection_fn_out){
  as_tibble(as.matrix(.dtm) %*% .projection_fn_out$projection)
}
```

# Task 1

## Data with Headers

```{r}
# Add headers
#claims_clean_headers <- claims_raw %>%
  #parse_data()
# Save the data into an RData file
#save(claims_clean_headers, file = '../data/claims-clean-headers.RData')
```

### Change Data With Headers Into a TF-IDF
```{r}
# Load the data
load('../data/claims-clean-headers.RData')
headers_clean <- claims_clean_headers %>%
  select(-c(1:5), -7)

# Convert to a TF-IDF
headers_tfidf <- headers_clean %>% 
  unnest_tokens(output = token, 
                input = text_clean, 
                token = 'words',
                stopwords = str_remove_all(stop_words$word, 
                                           '[[:punct:]]')) %>%
  mutate(token.lem = lemmatize_words(token)) %>%
  filter(str_length(token.lem) > 2) %>%
  count(.id, bclass, mclass, token.lem, name = 'n') %>%
  bind_tf_idf(term = token.lem, 
              document = .id,
              n = n) %>%
  pivot_wider(id_cols = c('.id', 'bclass', 'mclass'),
              names_from = 'token.lem',
              values_from = 'tf_idf',
              values_fill = 0)
```

### Partition the Data
```{r}
# Partition data
set.seed(102722)
partitions <- headers_tfidf %>% initial_split(prop = 0.8)

# Separate DTM from labels
test_dtm <- testing(partitions) %>%
  select(-.id, -bclass, -mclass)
test_labels <- testing(partitions) %>%
  select(.id, bclass, mclass)

# Same, training set
train_dtm <- training(partitions) %>%
  select(-.id, -bclass, -mclass)
train_labels <- training(partitions) %>%
  select(.id, bclass, mclass)
```

### PCA with Header Data
```{r}
# Set seed for reproducibility
set.seed(102722)

# Find projections based on training data
proj_out <- projection_fn(.dtm = train_dtm, .prop = 0.7)
train_dtm_projected <- proj_out$data

# How many components were used?
proj_out$n_pc
```

### Fit Header Data into Logistic Regression
```{r}
# Set seed for reproducibility
set.seed(102722)

# Regression on training data
train <- train_labels %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(train_dtm_projected)

# Fit the model
fit <- glm(bclass~., data = train, family = binomial)

```

### Project onto Test Data and Calculate Metrics
```{r}
# Set seed for reproducibility
set.seed(102722)

# Project test data
test_dtm_projected <- reproject_fn(.dtm = test_dtm, proj_out)

# Get predictions
preds <- predict(fit,
                 newdata = as.data.frame(test_dtm_projected),
                 type = 'response')

# Test-labels with predictions
pred_df <- test_labels %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(pred = as.numeric(preds)) %>%
  mutate(bclass.pred = factor(pred > 0.5, 
                              labels = levels(bclass)))

# Evaluate errors on test set
class_metrics <- metric_set(sensitivity, 
                            specificity, 
                            accuracy,
                            roc_auc)

# Calculate metrics
claims_clean_headers_metrics <- pred_df %>% class_metrics(truth = bclass, 
                  estimate = bclass.pred, 
                  pred, 
                  event_level = 'second')
claims_clean_headers_metrics

#save(claims_clean_headers_metrics, file = '../data/claims_clean_headers_metrics.RData')
```

## Data without Headers

### Change Data Without Headers Into a TF-IDF
```{r}
# Turn into a TF-IDF
no_headers_tfidf <- claims_clean %>% 
  unnest_tokens(output = token, 
                input = text_clean, 
                token = 'words',
                stopwords = str_remove_all(stop_words$word, 
                                           '[[:punct:]]')) %>%
  mutate(token.lem = lemmatize_words(token)) %>%
  filter(str_length(token.lem) > 2) %>%
  count(.id, bclass, mclass, token.lem, name = 'n') %>%
  bind_tf_idf(term = token.lem, 
              document = .id,
              n = n) %>%
  pivot_wider(id_cols = c('.id', 'bclass', 'mclass'),
              names_from = 'token.lem',
              values_from = 'tf_idf',
              values_fill = 0)
```

### Partition the Data
```{r}
# Partition data
  # Set seed for reproducibility
  set.seed(102722)
partitions1 <- no_headers_tfidf %>% initial_split(prop = 0.8)

# Separate DTM from labels
test_dtm1 <- testing(partitions1) %>%
  select(-.id, -bclass, -mclass)
test_labels1 <- testing(partitions1) %>%
  select(.id, bclass, mclass)

# Same, training set
train_dtm1 <- training(partitions1) %>%
  select(-.id, -bclass, -mclass)
train_labels1 <- training(partitions1) %>%
  select(.id, bclass, mclass)
```

### PCA without Headers Data
```{r}
# Find projections based on training data
proj_out1 <- projection_fn(.dtm = train_dtm1, .prop = 0.7)
train_dtm_projected1 <- proj_out1$data

# How many components were used?
proj_out1$n_pc
```

### Fit Data into Logistic Regression
```{r}
#regression
train1 <- train_labels1 %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(train_dtm_projected1)


fit1 <- glm(bclass~., data = train1, family = binomial)
```

### Project onto Test Data and Calculate Metrics
```{r}
# Project test data
test_dtm_projected1 <- reproject_fn(.dtm = test_dtm1, proj_out1)

# Get predictions
preds1 <- predict(fit1,
                 newdata = as.data.frame(test_dtm_projected1),
                 type = 'response')

# Test-labels with predictions
pred_df1 <- test_labels1 %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(pred = as.numeric(preds1)) %>%
  mutate(bclass.pred = factor(pred > 0.5, 
                              labels = levels(bclass)))

# Calculate metrics
claims_clean_no_headers_metrics <-pred_df1 %>% class_metrics(truth = bclass, 
                  estimate = bclass.pred, 
                  pred, 
                  event_level = 'second')

claims_clean_no_headers_metrics
#save(claims_clean_no_headers_metrics, file = '../data/claims_clean_no_headers_metrics.RData')
```

# Task 2

## Tokenize into Bigrams
```{r}
# Set seed for reproducibility
set.seed(102722)

# Tokenize into bigrams
headers_bigrams <- claims_clean_headers %>%
  select(.id, bclass, text_clean) %>%
  unnest_tokens(output = bigram, 
                input = text_clean, 
                token = 'ngrams', 
                n = 2, 
                stopwords = str_remove_all(stop_words$word, '[[:punct:]]'))
```

## Change Bigram Data into a TF-IDF
```{r}
# Count bigrams and compute TF-IDF
headers_bigrams_tfidf <- headers_bigrams %>%
  count(.id, bclass, bigram, name = 'n') %>%
  bind_tf_idf(term = bigram, 
              document = .id, 
              n = n) %>%
  filter(n>=5) %>% 
  pivot_wider(id_cols = c(.id, bclass),
              names_from = bigram,
              values_from = tf_idf,
              values_fill = 0)
```

## Partition the Data
```{r}
# Partition data
partitions_bigrams <- headers_bigrams_tfidf %>% initial_split(prop = 0.8)

train_dtm_bigrams <- training(partitions_bigrams) %>%
  select(-.id, -bclass)
train_labels_bigrams <- training(partitions_bigrams) %>%
  select(.id, bclass)

test_dtm_bigrams <- testing(partitions_bigrams) %>%
  select(-.id, -bclass)
test_labels_bigrams <- testing(partitions_bigrams) %>%
  select(.id, bclass)
```

## First Logistic Regression
```{r}
# Set seed for reproducibility
set.seed(102722)

# PCA projection for training bigram data
train_dtm_bigrams_sparse <- train_dtm_bigrams %>%
  as.matrix() %>%
  as('sparseMatrix') 
svd_out_bigrams <- sparsesvd(train_dtm_bigrams_sparse, rank=173)

# Training PCs data frame
train_dtm_projected2 <- svd_out_bigrams$u %*% diag(svd_out_bigrams$d)

# Assign column names
colnames(train_dtm_projected2) <- paste0("PC", 1:ncol(train_dtm_projected2))

# Regression with training data
train2 <- train_labels_bigrams %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(train_dtm_projected2)

fit2 <- glm(bclass~., data = train2, family = binomial)

# Re-projection of test data
reproject_fn1 <- function(.dtm, train_projected) {
  .dtm_sparse <- as(.dtm, "sparseMatrix")
  test_projected <- as.matrix(.dtm_sparse %*% train_projected$v %*% diag(1 / train_projected$d))
  colnames(test_projected) <- paste0("PC", 1:ncol(test_projected))
  return(test_projected)
}

# Test PCs data frame
test_dtm_projected2 <- reproject_fn1(.dtm = test_dtm_bigrams, svd_out_bigrams)
```

## Creating Log-odds
```{r}
# Put predicted probabilities into training dataset
train_bigram_preds <- train2 %>% 
  bind_cols(pred = as.numeric(predict(fit2, type = 'response'))) %>%
  mutate(log_odds = log(pred / (1 - pred)), #pred into log-odds
    bclass.pred = factor(pred > 0.5, 
                              labels = levels(bclass)))
```

## Second Logistic Regression
```{r}
# Regression on bclass with log-odds and 50 PC
train3 <- train_bigram_preds %>% 
  select(bclass, log_odds, PC1:PC50)

fit3 <- glm(bclass~., data = train3, family = binomial)
```

## Calculating Testing Data Metrics
```{r}
# Creating preds2
preds2 <- predict(fit2,
                 newdata = as.data.frame(test_dtm_projected2),
                 type = 'response')

# Creating pred_df2
pred_df2 <- test_labels_bigrams %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(pred = as.numeric(preds2)) %>%
  mutate(bclass.pred = factor(pred > 0.5, 
                              labels = levels(bclass)))

# Take projected test data and input log-odds
test <- cbind(pred_df2, test_dtm_projected2) %>%
  mutate(log_odds = log(pred / (1 - pred)))%>% 
  select(bclass, log_odds, PC1:PC50)

# Add predictions on test data
test_pred <-predict(fit3,
                 newdata = as.data.frame(test),
                 type = 'response')
test_pred_df <- test %>% 
  transmute(bclass = factor(bclass)) %>%
  bind_cols(pred = as.numeric(test_pred))%>%
  mutate(bclass.pred = factor(pred > 0.5, 
                              labels = levels(bclass)))

# Metrics
claims_clean_bigrams_metrics <- test_pred_df %>% class_metrics(truth = bclass, 
                  estimate = bclass.pred, 
                  pred, 
                  event_level = 'second')

claims_clean_bigrams_metrics

#save(claims_clean_bigrams_metrics, file = '../data/claims_clean_bigrams_metrics.RData')
```
