---
title: "primary task"
output: pdf_document
date: "2024-11-18"
---
```{r}
library(rvest)
library(tidyverse)
require(tidytext)
require(textstem)
require(rvest)
require(qdapRegex)
require(stopwords)
require(tokenizers)
library(tidymodels)
library(modelr)
library(Matrix)
library(sparsesvd)
library(glmnet)
library(e1071) # SVM library
library(yardstick)
library(keras)
library(tensorflow)
```


```{r}
# Loading the Data
source('preprocessing.R')
load("../data/claims-raw.RData")
load("../data/claims-clean-example.RData")
load('../data/claims-clean-headers.RData')
```

```{r}
# # function to parse html and clean text
# parse_fn <- function(.html){
#   read_html(.html) %>%
#     html_elements('p, h1, h2, h3, h4 , h5 , h6') %>%
#     html_text2() %>%
#     str_c(collapse = ' ') %>%
#     rm_url() %>%
#     rm_email() %>%
#     str_remove_all('\'') %>%
#     str_replace_all(paste(c('\n', 
#                             '[[:punct:]]', 
#                             'nbsp', 
#                             '[[:digit:]]', 
#                             '[[:symbol:]]'),
#                           collapse = '|'), ' ') %>%
#     str_replace_all("([a-z])([A-Z])", "\\1 \\2") %>%
#     tolower() %>%
#     str_replace_all("\\s+", " ")
# }
# 
# # function to apply to claims data
# parse_data <- function(.df){
#   out <- .df %>%
#     filter(str_detect(text_tmp, '<!')) %>%
#     rowwise() %>%
#     mutate(text_clean = parse_fn(text_tmp)) %>%
#     unnest(text_clean) 
#   return(out)
# }
# 
# nlp_fn <- function(parse_data.out){
#   out <- parse_data.out %>% 
#     unnest_tokens(output = token, 
#                   input = text_clean, 
#                   token = 'words',
#                   stopwords = str_remove_all(stop_words$word, 
#                                              '[[:punct:]]')) %>%
#     mutate(token.lem = lemmatize_words(token)) %>%
#     filter(str_length(token.lem) > 2) %>%
#     count(.id, bclass, mclass, token.lem, name = 'n') %>%
#     bind_tf_idf(term = token.lem, 
#                 document = .id,
#                 n = n) %>%
#     pivot_wider(id_cols = c('.id', 'bclass', 
#                             'mclass'),
#                 names_from = 'token.lem',
#                 values_from = 'tf_idf',
#                 values_fill = 0)
#   return(out)
# }
# #clean dataset
# claims_clean <- claims_raw %>% 
#   parse_data()
# # claims_clean_unigrams <- nlp_fn(claims_clean)
# ```
# 
# ```{r}
# #Tokenize tf_idf term matrix
# claims_clean_tfidf <- claims_clean %>%
#   mutate(text_clean = str_trim(text_clean)) %>%            
#   filter(str_length(text_clean) > 5) %>%                  
#   unnest_tokens(output = 'token', input = text_clean) %>% 
#   group_by(.id, bclass, mclass) %>%                       
#   count(token, name = "n") %>%                            
#   bind_tf_idf(term = token, document = .id, n = n) %>%    
#   pivot_wider(
#     id_cols = c(.id, bclass, mclass),                     
#     names_from = token,                                  
#     values_from = tf_idf,                                 
#     values_fill = 0) %>%
#   ungroup()         
```

### Tokenize into Unigrams
```{r}
# # Set seed for reproducibility
# set.seed(1234)
# Tokenize into unigrams
claims_unigrams <- claims_clean %>%
  select(.id, bclass, mclass, text_clean) %>%
  unnest_tokens(output = word,
                input = text_clean,
                token = 'words',
                stopwords = str_remove_all(stop_words$word,'[[:punct:]]'))

```

### Change Unigram Data into a TF-IDF
```{r}
# Count unigrams and compute TF-IDF
claims_unigrams_tfidf <- claims_unigrams %>%
  count(.id, bclass, mclass, word, name = 'n') %>%
  bind_tf_idf(term = word,
              document = .id,
              n = n) %>%
  filter(n>=5) %>%
  pivot_wider(id_cols = c(.id, bclass, mclass),
              names_from = word,
              values_from = tf_idf,
              values_fill = 0)
```

### Partition the Data
```{r}
set.seed(12345)
# Partition data
#headers_unigrams_tfidf
partitions_unigrams <- claims_clean_tfidf %>% initial_split(prop = 0.8)

train_dtm_unigrams <- training(partitions_unigrams) %>% 
  select(-.id, -bclass, -mclass)
train_labels_unigrams <- training(partitions_unigrams) %>% 
  select(.id, bclass, mclass)

test_dtm_unigrams <- testing(partitions_unigrams) %>% 
  select(-.id, -bclass, -mclass)
test_labels_unigrams <- testing(partitions_unigrams) %>% 
  select(.id, bclass, mclass)
```

### Dimensionality Reduction of training and testing splits
```{r}
# PCA projection for training unigram data
train_dtm_unigrams_sparse <- train_dtm_unigrams %>% 
  as.matrix() %>%
  as('sparseMatrix')
svd_out_unigrams <- sparsesvd(train_dtm_unigrams_sparse, rank=173) 

# Training PCs data frame
train_dtm_projected2 <- svd_out_unigrams$u %*% diag(svd_out_unigrams$d)


# Assign column names
colnames(train_dtm_projected2) <- paste0("PC", 1:ncol(train_dtm_projected2))
```

```{r}
# Function to reproject test data into the same space as training data
reproject_fn1 <- function(.dtm, svd_out) {
  # Convert test data into a sparse matrix
  .dtm_sparse <- as(.dtm, "sparseMatrix")
  
  # Reproject test data into the same space using SVD's V and D components
  test_projected <- as.matrix(.dtm_sparse %*% svd_out$v %*% diag(1 / svd_out$d))
  
  # Assign column names for principal components
  colnames(test_projected) <- paste0("PC", 1:ncol(test_projected))
  
  return(test_projected)
}

# Apply function to project test data
test_dtm_projected2 <- reproject_fn1(.dtm = test_dtm_unigrams, svd_out = svd_out_unigrams)
```

Test data is now represented in the same PCA-transformed space as the training data.

### Logistic Regression for Binary Model

```{r}
train <- train_labels_unigrams %>% 
  transmute(bclass = factor(bclass)) %>% 
  bind_cols(train_dtm_projected2)

fit <- glm(bclass ~ ., data = train, family = binomial)
```

```{r}
# store predictors and response as matrix and vector
x_train <- train %>% select(-bclass) %>%  as.matrix()
y_train <- train_labels_unigrams %>% pull(bclass)

# fit enet model
alpha_enet <- 0.3
log_reg_binary <- glmnet(x = x_train,
                  y = y_train,
                  family = 'binomial', 
                  alpha = alpha_enet)

# choose a constraint strength by cross-validation
set.seed(12345)
cvout <- cv.glmnet(x = x_train,
                   y = y_train,
                   family = 'binomial',
                   alpha = alpha_enet)

# store optimal strength
lambda_opt <- cvout$lambda.min

cvout
```

### Predictions for Binary Model
```{r}
# coerce to matrix
x_test <- as.matrix(test_dtm_projected2)

# compute predicted probabilities
preds <- predict(log_reg_binary,
                 s = lambda_opt,
                 newx = x_test,
                 type = 'response')

```

Now we can bind the test labels to the predictions:

```{r}
# store predictions in a data frame with true labels 
pred_df <- test_labels_unigrams %>% 
  transmute(bclass = factor(bclass)) %>% 
  bind_cols(pred = as.numeric(preds)) %>% 
  mutate(bclass.pred = factor(pred > 0.5,
                              labels = levels(bclass)))

# define classification metric panel
panel <- yardstick::metric_set(
  yardstick::sensitivity,
  yardstick::specificity,
  yardstick::accuracy,
  yardstick::roc_auc
)

# compute test set accuracy
pred_df %>%  panel(truth = bclass,
                   estimate = bclass.pred,
                   pred,
                   event_level = 'second')
  

```

## Multinomial regression for Multiclass Model
```{r}
# get multiclass labels 
y_train_multi <- train_labels_unigrams %>% pull(mclass)

# fit enet mdoel
alpha_enet <- 0.2
log_reg_multi <- glmnet(x = x_train,
                        y = y_train_multi,
                        family = 'multinomial',
                        alpha = alpha_enet)

# choose strenth by cross-validation
set.seed(12345)
cvout_multi <- cv.glmnet(x = x_train,
                         y = y_train_multi,
                         family = 'multinomial',
                         alpha = alpha_enet)

cvout_multi
```

# Predictions for Multi-class Model

```{r}
preds_multi <- predict(log_reg_multi,
                       s = cvout_multi$lambda.min,
                       newx = x_test,
                       type = 'response')
as_tibble(preds_multi[,,1]) %>% head(5)
```

Now we choose the most probable class as the prediction and cross-tabulate with the actual label.

```{r}
pred_class <- as_tibble(preds_multi[,,1]) %>% 
  mutate(row = row_number()) %>% 
  pivot_longer(-row,
               names_to = 'label',
               values_to = 'probability') %>% 
  group_by(row) %>% 
  slice_max(probability, n = 1) %>% 
  pull(label)

pred_tbl <- table(pull(test_labels_unigrams, mclass), pred_class)

pred_tbl
```
### Calculate accuracy metrics
```{r}
# Ensure labels in the confusion matrix are aligned
true_labels <- factor(pull(test_labels_unigrams, mclass), levels = levels(test_labels_unigrams$mclass))
predicted_labels <- factor(pred_class, levels = levels(test_labels_unigrams$mclass))

# Create confusion matrix
pred_tbl <- table(true_labels, predicted_labels)

# Calculate accuracy
accuracy_test <- sum(diag(pred_tbl)) / sum(pred_tbl)
print(paste("Accuracy:", round(accuracy_test, 4)))

# Calculate precision per class
precision <- diag(pred_tbl) / rowSums(pred_tbl)

# Calculate recall (sensitivity) per class
recall <- diag(pred_tbl) / colSums(pred_tbl)

# Calculate F1 score per class
f1_score <- 2 * (precision * recall) / (precision + recall)

# Macro-averaged Precision, Recall, and F1 Score
## unweighted mean of precision, recall, and F1 score across all classes

macro_precision <- mean(precision, na.rm = TRUE)
macro_recall <- mean(recall, na.rm = TRUE)
macro_f1 <- mean(f1_score, na.rm = TRUE)

print(paste("Macro Precision:", round(macro_precision, 4)))
print(paste("Macro Recall:", round(macro_recall, 4)))
print(paste("Macro F1 Score:", round(macro_f1, 4)))
```


### Save the models
```{r}
# Save the logistic regression binary model
save(log_reg_binary, file = "../results/log_reg_binary.RData")

# Save the multinomial regression multi-class model
save(log_reg_multi, file = "../results/log_reg_multi.RData")
```

# Prediction on claims-test.RData
```{r}
# Load in the new test data
load("../data/claims-test.RData")
```

## Clean the test data
```{r}
# Clean test data
#claims_test_clean <- claims_test %>%
  #parse_data()

claims_test_clean %>% head(5)
```

## Tokenize
```{r}
# Set seed for reproducibility
set.seed(1234)
# Tokenize into unigrams
test_unigrams <- claims_test_clean %>% 
  select(.id, text_clean) %>% 
  unnest_tokens(output = word, 
                input = text_clean, 
                token = 'words', 
                stopwords = str_remove_all(stop_words$word,'[[:punct:]]'))
```

## Convert to TF-IDF
```{r}
# Count unigrams and compute TF-IDF
test_unigrams_tfidf <- test_unigrams %>% 
  count(.id, word, name = 'n') %>% 
  bind_tf_idf(term = word,
              document = .id, 
              n = n) %>% 
  filter(n>=5) %>%
  pivot_wider(id_cols = c(.id), 
              names_from = word,
              values_from = tf_idf,
              values_fill = 0)
```

### Dimensionality Reduction of Test Data
```{r}
test_unigrams_tfidf_mtx <- test_unigrams_tfidf %>% select(-.id)

# PCA projection for training unigram data
test_dtm_unigrams_sparse <- test_unigrams_tfidf_mtx %>% 
  as.matrix() %>%
  as('sparseMatrix')


svd_out_unigrams <- sparsesvd(test_dtm_unigrams_sparse, rank=173)

# project test data onto PCs
test_dtm_projected<- reproject_fn1(.dtm = test_unigrams_tfidf_mtx, svd_out = svd_out_unigrams)
```

### Make out predictions for both models
```{r}
## For binary model
# coerce to matrix
x_test_actual <- as.matrix(test_dtm_projected)

# compute predicted probabilities
preds_actual <- predict(log_reg_binary,
                 s = lambda_opt,
                 newx = x_test_actual,
                 type = 'response')

# get the labels
pred_df_binary <-  bind_cols(.id = test_unigrams_tfidf$.id, pred = as.numeric(preds_actual)) %>% 
  mutate(bclass.pred = factor(pred > 0.5, 
                              labels = levels(test_labels_unigrams$bclass))) %>% 
  select(.id, bclass.pred)

## For multi-class model
preds_multi_actual <- predict(log_reg_multi,
                       s = cvout_multi$lambda.min,
                       newx = x_test_actual,
                       type = 'response')

# get the labels for multi classes
pred_class_actual <- as_tibble(preds_multi_actual[,,1]) %>% 
  mutate(row = row_number()) %>% 
  pivot_longer(-row,
               names_to = 'label',
               values_to = 'probability') %>% 
  group_by(row) %>% 
  slice_max(probability, n = 1) %>% 
  pull(label)

pred_df_multi <- tibble(.id = test_unigrams_tfidf$.id,
                        mclass.pred = factor(pred_class_actual,
                                             levels = colnames(preds_multi_actual)))

# Combine binary and multi-class predictions
pred_df <- left_join(pred_df_binary, pred_df_multi, by = ".id")

# Save predictions
save(pred_df, file = "../results/preds-group2.RData")
```



